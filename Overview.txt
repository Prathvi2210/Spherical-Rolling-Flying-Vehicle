# SRFV-Project
This is a research project for developing a prototype of Spherical Rolling Flying Vehicle.  

First: Synexens Drivers issue with ROS2.

Second: RPi 4 model B, Ubuntu 20.04, Synexens CS20, Mavros, Ardupilot, ROS Noetic (ROS1)
 Synexens CS20 being a new, different sensor, support was minimal and debugging was hard.
Progress done: Synexens drivers installed and working, feed was visible via ROS Bridge on a custom webapp. Pointcloud not visualized in webapp yet.
RTABmap built and launched multiple times with different arguments
MAVROS working. connected with Ardupilot. Need to set stream rate everytime it is launched for rostopic data.
All rostopics working and visible.
Issues: Synexens CS20 not having RGB feed, It is a depth camera using TOF technology with near IR light and giving pseudo pointclouds. It is not a lidar, it uses the mirror-lens technology similar to what is found in solid-state lidars. It makes a calculated pointcloud data as output. It doesn't have inbuild pcd output, it calculates them. So the outputs are depth feed and ir feed.
RTAB map uses Depth and RGB for texture scanning and loop closures. Usinf IR instead of RGB makes the texture scanning difficult. Although Synexens CS20 is ideal for indoor navigation the mapping fails miserably.
Transform trees are hauntingly broken for ROS Noetic versions. At times I have had to manually initiate 5 dynamic connections between different tree-nodes. This is due to the synexens ROS1 driber chocking and the ROS -RTAB combo not being able to fix the timestamp issues and not recovering from the fallen TF trees: according to ChatGPT.
These 2 errors primarily gave rise to issues after launch of RTABmap algo.
What I achieved till now: Due to headless version of Ubuntu on RPi4, I couldn't visualize the mapping. So I made a provision: Virtual Machine VM on my windows laptop which also had Ubuntu 20.04 desktop and ROS Noetic desktop (with RViz). I set the ROS master and ROS_IP on both devices and launched RTAB on RPi without RViz and started RViz on VM and the data could be visualized there. 
I added TF display: it works fine, showed the axes. Then I added the pointcloud2 display: when I set topic to /camera1/pointcloud it was showing the pcd output. When I set it to /rtabmap/cloudmap it showed nothing.
Possible reasons and solutions in chatgpt SRFV project:
    ✅ 1. No map has been built yet (most common)
    /rtabmap/cloudmap is empty until RTAB-Map has created at least one node.
    Check:
    rostopic echo /rtabmap/cloudmap\
    If output is blank → RTAB-Map hasn't created poses/nodes yet.
    Fix:
    Move the camera around so RTAB-Map can initialize odom + create first keyframe.
    ✅ 2. RTAB-Map not receiving correct topics (depth + info mismatch)
    If your topics are wrong, RTAB-Map will start but not generate map updates.
    Check:
    rosnode info /rtabmap
    Verify these are connected:
    /camera/depth_raw
    /camera/depth_info
    /camera/ir_raw or /camera/rgb_image (if subscribe_rgb:=true)
    /camera/odom or /rtabmap/odom
    If any of these are not connected, fix topic names.
    ✅ 3. TF is incomplete → RTAB-Map cannot compute global map
    You can see TF axes, but mapping needs exact chain:
    camera_link → base_link → odom → map
    Check:
    rosrun tf view_frames
    evince frames.pdf
    If any link is missing → /cloudmap will stay empty.
    ✅ 4. Cloud output disabled in your RTAB-Map launch
    If you turned off cloud publishing:
    Check parameters in your rtabmap.launch:
    <param name="publish_cloud_map" type="bool" value="true" />
    <param name="publish_clouds" type="bool" value="true" />
    <param name="cloud_voxel_size" type="double" value="0.02" />
    If publish_cloud_map=false → /rtabmap/cloudmap never publishes.
    ✅ 5. rtabmapviz or RViz plugin not receiving updates
    Sometimes RViz won’t show because cloud rate = 0.
    Fix:
    rosparam set /rtabmap/cloudmap_voxel_size 0.05
    rosparam set /rtabmap/cloud_decimation 2
    Then restart RTAB-Map.
    ✅ 6. Odometry not working
    No odometry → RTAB-Map will not create map → empty cloudmap.
    Check:
    rostopic hz /rtabmap/odom
    If no data → fix odometry source:
    rgbd_odometry
    icp_odometry
    external odom (wheel/IMU)
    ✅ 7. Wrong /rtabmap namespace or using ROS1 bridge incorrectly
    If you run ROS1 RTAB-Map but RViz on ROS2 VM:
    /rtabmap/cloudmap must be bridged through ros1_bridge.
    Check:
    ros2 topic list
    If /rtabmap/cloudmap is not appearing on ROS2 side → bridge issue.

    
Third try to build this project from the start: RPi4 model B, ubuntu 22.04, ROS2 Humble, mavros2-PX4, intel RealSense D455(established sensor instead of Synexens)

ROS installed from deb- documentation
Intel Realsense issue: Building the sdk from source: kernel patching command not working: fatal: You need to specify a tag name.
Proceeding manually to skip this part and build the sdk

RPi freezes with all these installations. It should have worked theoretically at its limits with camera sdk, SLAM and ROS but it cant even handle the intel camera in ROS. Keeps freezing and quitting. 
Tried to use the synexens camera in ROS2 environment, whole installation and ROS integration is mentioned in a file in this repo. This camera software stack was lighter and easier to run. Depth feed and pointcloud are very easily visible in Rviz which is a sign of good integration of camera SDK and ROS. However after trying multiple failed configurations of RTABMap it constantly tried looking for RGB topics which the synexens camera can't provide. For a depth camera that can provide pointcloud data but no RGB, there is no suitable SLAM algorithm apparent to me currently.
Without RGB feed VSLAM is problematic, there is no case of RTAB running without RGB feed.
Several other SLAM algorithms can build 3D maps using only depth images or point clouds from sensors like the Synexens CS20:
 Direct Depth SLAM (DDS)
 Cartographer ROS (3D Mode)
 Point-SLAM
 LiDAR SLAM Options (Point Cloud)

For real time mapping on UAVs, DDS and LiDar based both are not recommended. From the remaining, they both are not able to run on an RPi system, need more power. Atleast cartographer can be started on an RPi with 'aggressive tuning' but again it will not be robust. Need to have a more powerful edge computer for this.

CS20 is a forward‑looking ToF depth camera: 640×480, ~70–90° FOV, 0.1–5 m range, giving a dense pointcloud in a single sector
Classic LiDAR SLAM (LOAM, LeGO-LOAM, many 2D mappers) assume:
 360° or at least wide horizontal coverage.
 Fixed vertical beam layout (e.g., 16/32/64 rings).
 Clear ground plane for segmentation and motion constraints.
Then only solution is to use 2D mapping to accomodate this on RPi
